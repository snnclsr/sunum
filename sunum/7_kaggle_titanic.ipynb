{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kütüphanelerin Eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verilerin Okunması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# İşimizi kolaylaştırması açısından etiket(label) değerlerini ayrı bir şekilde tutuyoruz.\n",
    "y = train_data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Öznitelik Çıkarımı(Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_pivot = train_data.pivot_table(index=\"Sex\", values=\"Survived\")\n",
    "sex_pivot.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = train_data[train_data[\"Survived\"] == 1]\n",
    "died = train_data[train_data[\"Survived\"] == 0]\n",
    "\n",
    "survived[\"Age\"].plot.hist(alpha=0.5, color='red', bins=50)\n",
    "died[\"Age\"].plot.hist(alpha=0.5, color='blue', bins=50)\n",
    "plt.legend([\"Survived\", \"Died\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_points = [-1, 0, 5, 12, 18, 35, 60, 80]\n",
    "label_names = [\"Missing\", \"Baby\", \"Child\", \"Teen\", \"Young_adult\", \"Adult\", \"Senior\"]\n",
    "train_data[\"Age\"] = train_data[\"Age\"].fillna(-0.5)\n",
    "train_data[\"Age_categories\"] = pd.cut(train_data[\"Age\"], cut_points, label_names)\n",
    "\n",
    "test_data[\"Age\"] = test_data[\"Age\"].fillna(-0.5)\n",
    "test_data[\"Age_categories\"] = pd.cut(test_data[\"Age\"], cut_points, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Age_categories\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cat_pivot = train_data.pivot_table(index=\"Age_categories\", values=\"Survived\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(221)\n",
    "age_cat_pivot.plot(kind='bar', ax=ax)\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "sex_pivot.plot(kind='bar', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Sınırlı sayıda değer alan verilere kategorik veri deniyor. Örneğin insanların hangi marka arabaya sahip oldukları hakkında bir anket yapsanız sonuçlar kategorik olurdu(Toyota, Renault vs.). Çoğu makine öğrenme algoritmasını uygularken bu değerleri *\"encode\"* etmez isek hata ile karşılaşırız. One-Hot Encoding, kategorik verileri encode etmek için kullanılan yöntemlerden birisi.\n",
    "\n",
    "<table style=\"width:20%; margin-top:10px; margin-left:0px;\">\n",
    "    <tr>\n",
    "    <td> \n",
    "        **Toyota ** : \n",
    "    </td>\n",
    "    <td>\n",
    "        1-0-0-0\n",
    "    </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td> \n",
    "        **Renault ** : \n",
    "    </td>\n",
    "    <td>\n",
    "        0-1-0-0\n",
    "    </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "    <td> \n",
    "        **Honda ** : \n",
    "    </td>\n",
    "    <td>\n",
    "        0-0-1-0\n",
    "    </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td> \n",
    "        **BMW ** : \n",
    "    </td>\n",
    "    <td>\n",
    "        0-0-0-1\n",
    "    </td>\n",
    "       </tr>\n",
    "</table>\n",
    "Yukarıda ki tabloda gördüğünüz üzere ilgili sınıfın olduğu indekse 1, geri kalanlara 0 yazıyoruz. Daha sonra oluşturduğumuz bu veriyi veri setimize yeni bir sütun olarak ekliyoruz.\n",
    "Biz de bu yazı boyunca bu yönteme başvuracağız. Bu yöntemi uygulamak içinse [pd.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) fonksiyonunu kullanacağız.\n",
    "\n",
    "Daha fazla bilgi almak isterseniz [bu](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding) yazıyı okuyabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dummies(df, column_name):\n",
    "    dummies = pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = create_dummies(train_data, \"Age_categories\")\n",
    "test_data = create_dummies(test_data, \"Age_categories\")\n",
    "\n",
    "train_data = create_dummies(train_data, \"Sex\")\n",
    "test_data = create_dummies(test_data, \"Sex\")\n",
    "\n",
    "train_data = create_dummies(train_data, \"Pclass\")\n",
    "test_data = create_dummies(test_data, \"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "train_data[cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\n",
    "test_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "train_data = create_dummies(train_data, \"Embarked\")\n",
    "test_data = create_dummies(test_data, \"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_cols = [\"SibSp\", \"Parch\", \"Survived\"]\n",
    "explore = train_data[explore_cols].copy()\n",
    "\n",
    "explore[\"family_size\"] = explore[[\"SibSp\", \"Parch\"]].sum(axis=1)\n",
    "\n",
    "pivot = explore.pivot_table(index=\"family_size\", values=\"Survived\")\n",
    "pivot.plot.bar(ylim=(0,1), yticks=np.arange(0,1,.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_family(df):\n",
    "    is_alone = []\n",
    "    for val in df[[\"SibSp\", \"Parch\"]].sum(axis=1):\n",
    "        if val == 0:\n",
    "            is_alone.append(1)\n",
    "        else:\n",
    "            is_alone.append(0)\n",
    "    \n",
    "    df[\"is_alone\"] = is_alone\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = process_family(train_data)\n",
    "test_data = process_family(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = create_dummies(train_data, \"is_alone\")\n",
    "test_data = create_dummies(test_data, \"is_alone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = train_data[train_data[\"Survived\"] == 1]\n",
    "died = train_data[train_data[\"Survived\"] == 0]\n",
    "\n",
    "survived[\"Fare\"].plot.hist(alpha=0.5, range=[0, 200], color='red', bins=10)\n",
    "died[\"Fare\"].plot.hist(alpha=0.5, range=[0,200], color='blue', bins=10)\n",
    "\n",
    "plt.legend([\"Survived\", \"Died\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_points = [0, 12, 50, 100, 1000]\n",
    "label_names = [\"0-12\", \"12-50\", \"50-100\", \"100+\"]\n",
    "def process_fare(df, cut_points, label_names):\n",
    "    df[\"Fare\"] = pd.cut(df[\"Fare\"], cut_points, labels=label_names) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = process_fare(train_data, cut_points, label_names)\n",
    "test_data = process_fare(test_data, cut_points, label_names)\n",
    "\n",
    "train_data = create_dummies(train_data,\"Fare\")\n",
    "test_data = create_dummies(test_data, \"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Cabin\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"Cabin_type\"] = train_data[\"Cabin\"].str[0]\n",
    "test_data[\"Cabin_type\"] = test_data[\"Cabin\"].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"Cabin_type\"] = train_data[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "test_data[\"Cabin_type\"] = test_data[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "\n",
    "train_data = create_dummies(train_data, \"Cabin_type\")\n",
    "test_data = create_dummies(test_data, \"Cabin_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Name\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Büyük-küçük harfler ve nokta ile biten kelimeleri eşleştir.\n",
    "pattern =  '([A-Za-z]+)\\.'\n",
    "extracted_titles = train_data[\"Name\"].str.extract(pattern, expand=False)\n",
    "print(extracted_titles[:5])\n",
    "titles = {\n",
    "    \"Mr\" :         \"Mr\",\n",
    "    \"Mme\":         \"Mrs\",\n",
    "    \"Ms\":          \"Mrs\",\n",
    "    \"Mrs\" :        \"Mrs\",\n",
    "    \"Master\" :     \"Master\",\n",
    "    \"Mlle\":        \"Miss\",\n",
    "    \"Miss\" :       \"Miss\",\n",
    "    \"Capt\":        \"Officer\",\n",
    "    \"Col\":         \"Officer\",\n",
    "    \"Major\":       \"Officer\",\n",
    "    \"Dr\":          \"Officer\",\n",
    "    \"Rev\":         \"Officer\",\n",
    "    \"Jonkheer\":    \"Royalty\",\n",
    "    \"Don\":         \"Royalty\",\n",
    "    \"Sir\" :        \"Royalty\",\n",
    "    \"Countess\":    \"Royalty\",\n",
    "    \"Dona\":        \"Royalty\",\n",
    "    \"Lady\" :       \"Royalty\"\n",
    "}\n",
    "train_data[\"Title\"] = extracted_titles.map(titles)\n",
    "extracted_titles = test_data[\"Name\"].str.extract(pattern, expand=False)\n",
    "test_data[\"Title\"] = extracted_titles.map(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = create_dummies(train_data, \"Title\")\n",
    "test_data = create_dummies(test_data, \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eşdoğrusallık(Collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df):\n",
    "    corr = df.corr()\n",
    "    \n",
    "    sns.set(style=\"white\")\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Birazdan kaggle'a tahminlerimizi kaydedeceğiz. Orada kullanabilmek adına yolcuların id'lerini çıkarmadan\n",
    "# önce saklayalım.\n",
    "passenger_id = test_data[\"PassengerId\"]\n",
    "drop_cols = ['PassengerId','Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    "             'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_categories', 'is_alone',\n",
    "            'Cabin_type', 'Title']\n",
    "\n",
    "train_data = train_data.drop(drop_cols, axis=1)\n",
    "test_data = test_data.drop(drop_cols, axis=1)\n",
    "\n",
    "train_data = train_data.drop([\"Survived\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop([\"Cabin_type_Unknown\", \"Cabin_type_T\"], axis=1)\n",
    "test_data = test_data.drop([\"Cabin_type_Unknown\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "selector = RFECV(rf, cv=10)\n",
    "selector.fit(train_data, y)\n",
    "\n",
    "opt_cols = train_data.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellerin oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data[opt_cols], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "models = []\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "predictions.append([pd.DataFrame(lr_pred), 'LR'])\n",
    "models.append(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "predictions.append([pd.DataFrame(knn_pred), 'KNN'])\n",
    "models.append(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "predictions.append([pd.DataFrame(rfc_pred), 'RFC'])\n",
    "models.append(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in predictions:\n",
    "    acc = accuracy_score(y_test, pred[0])\n",
    "    print(pred[1], ' : ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_submission_file(models):\n",
    "    for model in models:\n",
    "        prediction = model.predict(test_data[opt_cols])\n",
    "        df = {\"PassengerId\": passenger_id, \"Survived\": prediction}\n",
    "        submission = pd.DataFrame(df)\n",
    "        name = \"submission\" + model.__class__.__name__ + \".csv\"\n",
    "        submission.to_csv(name, index=False)\n",
    "        \n",
    "save_submission_file(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
